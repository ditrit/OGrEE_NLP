{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ogree_wiki' from 'c:\\\\Users\\\\thoxy\\\\OneDrive\\\\Documents\\\\IMT-PJENT\\\\OGrEE_NLP\\\\ogree_wiki.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import importlib\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import ogree_wiki as wiki\n",
    "importlib.reload(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_DEFAULT = {\n",
    "                    \"ACTION_POSITIVE\" : [\"make\",\"build\",\"put\",\"place\"],\n",
    "                    \"ACTION_NEGATIVE\" : [\"remove\", \"delete\"], \n",
    "                    \"ALTERATION\" : [\"modify\", \"change\",\"move\",\"set\",\"rename\",\"rotate\"]\n",
    "                    }\n",
    "\n",
    "ACTIONS_CLI = {\n",
    "                \"ACTION_POSITIVE\" : \"+\",\n",
    "                \"ACTION_NEGATIVE\" : \"-\"\n",
    "                }\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.5\n",
    "\n",
    "PARAMETERS_DICT = {\n",
    "            \"name\" : [\"name\",\"called\"],\n",
    "            \"position\" : [\"position\",\"at\",\"located\"],\n",
    "            \"rotation\" : [\"rotation\",\"turned\",\"degree\"],\n",
    "            \"size\" : [\"size\",\"dimensions\"],\n",
    "            \"template\" : [\"template\"],\n",
    "            \"axisOrientation\" : [\"orientation\"], #CAN BE IMPROVED !!!!!!!!!\n",
    "            \"slot\" : [\"slot\"],\n",
    "            \"color\" : [\"color\"], #Est-ce qu'on rajoute des couleurs genre red, green, grey, ...?\n",
    "            \"unit\" :  [\"unit\"],    # C'est quoi le mieux ? [\"t\",\"m\",\"f\",'metre', \"tilde\", \"feet\"],\n",
    "            \"side\" : [\"side\"],\n",
    "            \"temperature\" : [\"temp\",\"temperature\", \"Â°C\", \"K\",\"F\"],\n",
    "            \"reserved\" : [\"reserved\"],\n",
    "            \"technical\" : [\"technical\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexAction(processed_entry : type(nlp(\"\")), indexAction : int, list_index_entities : list) -> int :\n",
    "    # identify relations for each entity recognized\n",
    "    currentIndexes = list_index_entities[::]\n",
    "    counter = 0\n",
    "    while counter < 3 :\n",
    "        for i in range(len(list_index_entities)) :\n",
    "            currentWord = processed_entry[currentIndexes[i]].head\n",
    "            currentIndexes[i] = list(processed_entry).index(currentWord)\n",
    "        counter += 1\n",
    "\n",
    "    currentIndexesBool = [index == indexAction for index in currentIndexes]\n",
    "    if sum(currentIndexesBool) >= 2 :\n",
    "        currentIndexDistance = [(abs(indexAction - list_index_entities[i]),list_index_entities[i]) for i in range(len(currentIndexes)) if currentIndexesBool[i] == True]\n",
    "        return min(currentIndexDistance)[1]\n",
    "    elif sum(currentIndexesBool) == 1:\n",
    "        return list_index_entities[currentIndexesBool.index(True)]\n",
    "    else :\n",
    "        raise Exception(\"Interpretation issue : no relation found, please try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexMainSubject(processed_entry : type(nlp(\"\")), indexAction : int, dictioIndexKeyWords : dict) -> int :\n",
    "\n",
    "    counter = 0\n",
    "    currentIndexes = {index:index for index,_ in dictioIndexKeyWords.items() if processed_entry[index].pos_ != \"VERB\"}\n",
    "    currentWords = {index:processed_entry[index] for index in currentIndexes.keys()}\n",
    "    while (not indexAction in currentIndexes.values()) and counter < 3 :\n",
    "        currentWords = {originIndex : processed_entry[currentIndex].head for originIndex,currentIndex in currentIndexes.items()}\n",
    "        currentIndexes = {originIndex : currentWords[originIndex].i for originIndex,_ in currentIndexes.items()}\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 3 :\n",
    "        raise Exception(\"Did not find the main subject\")\n",
    "    \n",
    "    if list(currentIndexes.values()).count(indexAction) != 1 :\n",
    "        listIndexesRemaining = [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction and originIndex > indexAction]\n",
    "        return listIndexesRemaining[0]\n",
    "    else :\n",
    "        return [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchEntity(processed_entry : type(nlp(\"\")), KEY_WORDS_ENTRY : dict, currentIndex : int):\n",
    "    if currentIndex in KEY_WORDS_ENTRY.keys() and KEY_WORDS_ENTRY[currentIndex] == \"entity\":\n",
    "        return currentIndex\n",
    "    else:\n",
    "        for child in processed_entry[currentIndex].children:\n",
    "            index = searchEntity(processed_entry, KEY_WORDS_ENTRY, child.i)\n",
    "            if index != None:\n",
    "                return index\n",
    "        return None\n",
    "\n",
    "def searchName(processed_entry : type(nlp(\"\")), KEY_WORDS_ENTRY : dict, currentIndex : int):\n",
    "    if processed_entry[currentIndex].is_upper or processed_entry[currentIndex].pos_ == \"PROPN\" :\n",
    "        return currentIndex\n",
    "    else:\n",
    "        for child in processed_entry[currentIndex].children:\n",
    "            index = searchName(processed_entry, child.i)\n",
    "            if index != None:\n",
    "                return index\n",
    "        return None\n",
    "    \n",
    "def testRelation(index1 : int, index2 : int, relationType : str, hierarchyPosition : dict) -> bool :\n",
    "    if relationType == \"appartenance\" and hierarchyPosition[index2] < hierarchyPosition[index1]:\n",
    "        return True\n",
    "    elif relationType == \"next\" and hierarchyPosition[index2] == hierarchyPosition[index1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def findRelations(processed_entry : type(nlp(\"\")), dictEntities : dict, indexAction : int) -> dict:\n",
    "\n",
    "    RELATIONS = {\n",
    "        \"appartenance\" : [\"in\", \"inside\"],\n",
    "        \"next\" : [\"next\"]\n",
    "    }\n",
    "    \n",
    "    dictRelations = {index : None for index in dictEntities.keys()}\n",
    "\n",
    "    for index in dictEntities.keys():\n",
    "        for relation in RELATIONS.keys():\n",
    "            for ancestor in processed_entry[index].ancestors:\n",
    "                if max([ancestor.similarity(nlp(word)[0]) > SIMILARITY_PARAMETER for word in RELATIONS[relation]]):\n",
    "                    dictRelations[index] = relation\n",
    "                    break\n",
    "\n",
    "    global INDEX_MAIN_ENTITY\n",
    "\n",
    "    withoutRelationCounter = list(dictRelations.values()).count(None)\n",
    "    if  withoutRelationCounter != 1:\n",
    "        dictWithoutRelations = {index : relation for (index,relation) in dictRelations.items() if relation == None}\n",
    "        if withoutRelationCounter == 0 :\n",
    "            dictWithoutRelations = dictEntities\n",
    "        INDEX_MAIN_ENTITY = findIndexMainSubject(processed_entry, indexAction, dictWithoutRelations)\n",
    "\n",
    "    INDEX_MAIN_ENTITY = [index for index,relation in dictRelations.items() if relation == None][0]\n",
    "\n",
    "    hierarchyPosition = {index : list(wiki.ENTITIES.keys()).index(entity) for index, entity in dictEntities.items()}\n",
    "    finalRelations = dict()\n",
    "\n",
    "    for index, relation in dictRelations.items() : \n",
    "        if index == INDEX_MAIN_ENTITY:\n",
    "            continue\n",
    "        for token in processed_entry[index].ancestors :\n",
    "            if token.i in dictEntities.keys(): \n",
    "                if testRelation(token.i, index, relation, hierarchyPosition):\n",
    "                    finalRelations[index] = (token.i, relation)\n",
    "                else:\n",
    "                    finalRelations[index] = (token.i, \"ERROR\")\n",
    "                break\n",
    "            elif token.i == indexAction:\n",
    "                if testRelation(INDEX_MAIN_ENTITY, index, relation, hierarchyPosition):\n",
    "                    finalRelations[index] = (INDEX_MAIN_ENTITY, relation)\n",
    "                else:\n",
    "                    finalRelations[index] = (INDEX_MAIN_ENTITY, \"ERROR\")\n",
    "                break\n",
    "        if not index in finalRelations :\n",
    "            finalRelations[index] = (INDEX_MAIN_ENTITY, relation)\n",
    "\n",
    "    return finalRelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(processed_entry : type(nlp(\"\")), dictioEntities : dict, indexesMain : list) -> int :\n",
    "\n",
    "    def findClose(processed_entry : type(nlp(\"\")), index : int) -> (int|None) :\n",
    "        if index +1 <= len(processed_entry)-1 :\n",
    "            if processed_entry[index+1].is_upper or processed_entry[index+1].pos_ == \"PROPN\" :\n",
    "                return index+1\n",
    "        if 0 <= index -1 :\n",
    "            if processed_entry[index-1].is_upper or processed_entry[index-1].pos_ == \"PROPN\" :\n",
    "                return index-1\n",
    "        return None\n",
    "    \n",
    "\n",
    "    def findAttachedEntity(processed_entry : type(nlp(\"\")), index : int) -> (int|None) : \n",
    "        counter = 0\n",
    "        isFound = False\n",
    "        currentIndex = index\n",
    "        currentWord = processed_entry[currentIndex]\n",
    "        while (not isFound) and counter < 3 :\n",
    "            currentWord = processed_entry[currentIndex].head\n",
    "            currentIndex = currentWord.i\n",
    "            if str(currentWord) in dictioEntities.values() :\n",
    "                return currentIndex\n",
    "            if currentWord.pos_ == \"VERB\" and currentIndex == indexesMain[1] : \n",
    "                return indexesMain[0]\n",
    "            counter += 1\n",
    "        return None\n",
    "    \n",
    "    EXPLICIT =  PARAMETERS_DICT[\"name\"]\n",
    "    IMPLICIT = [\"current\",\"main\"]\n",
    "\n",
    "    dictioEntityNames = {}\n",
    "        \n",
    "    for index,entity in dictioEntities.items() :\n",
    "    # if the name if right beside the entity\n",
    "        resultIndex = findClose(processed_entry, index)\n",
    "        if resultIndex != None :\n",
    "            dictioEntityNames[index] = resultIndex\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if not all names found\n",
    "\n",
    "        for index,token in enumerate(processed_entry) : # look for keyword\n",
    "\n",
    "            if processed_entry[index].is_upper or processed_entry[index].pos_ == \"PROPN\" :\n",
    "                indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                    dictioEntityNames[indexAttachedEntity] = index\n",
    "            \n",
    "            # if the token is a synonym of called\n",
    "            if sum([token.similarity(nlp(word)[0]) > SIMILARITY_THRESHOLD for word in EXPLICIT]) >= 1 :\n",
    "                resultIndex = findClose(processed_entry, index)\n",
    "                if resultIndex != None :\n",
    "                    indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                    if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                        dictioEntityNames[indexAttachedEntity] = resultIndex\n",
    "\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if still not all names found\n",
    "        pass\n",
    "    # TODO : get current names\n",
    "\n",
    "    # TODO : check for implicit words now\n",
    "    \n",
    "    return dictioEntityNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(processed_entry : type(nlp(\"\")), index : int, attachedEntity : str, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    # search for keywords to the right and left to split whole sentence into parts where to look for param entries\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    previous_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    LENGTH_CRITERIA = 2\n",
    "    if attachedEntity == \"device\" :\n",
    "        LENGTH_CRITERIA = 1\n",
    "    position_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    if not (len(position_list) == LENGTH_CRITERIA or (len(position_list) == 3 and attachedEntity == \"rack\")):\n",
    "        position_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in previous_words]))\n",
    "        if not (len(position_list) == LENGTH_CRITERIA or (len(position_list) == 3 and attachedEntity == \"rack\")) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            position_list = position_list_left\n",
    "    result = [float(coord) for coord in position_list] if position_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axisOrientation(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    # We search the axis Orientation\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #An axis Orientation  can be any combinason of [+/-]x[+/-]y. eg: +x+y or -x+y\n",
    "    print(\" \".join([str(token) for token in next_words]))\n",
    "    axisOrientationList =  re.findall(\" (-x|\\+[ *]x)[ *](-y|\\+[ *]y)\", \" \".join([str(token) for token in next_words]))\n",
    "    #If we didn't find an axis orientation, we need to seek it in the second part of the sentence\n",
    "    if len(axisOrientationList) ==0 :\n",
    "        axisOrientationList = re.findall(\"(-x|\\+[ *]x)[ *](-y|\\+[ *]y)\", \" \".join([str(token) for token in last_words]))\n",
    "        #If we still didn't find it, we need to raise an error\n",
    "        if len(axisOrientationList) ==0 :\n",
    "            raise Exception(\"Wrong axisOrientation format entered\")\n",
    "    \n",
    "    #We need to raise an error if we find only one coordonate\n",
    "    if len(axisOrientationList[0]) < 2:\n",
    "        raise Exception(\"Only one coordinate was found\")\n",
    "    #Even if several axis Orientations where found, we always take the first one\n",
    "    return axisOrientationList[0][0].replace(\" \", \"\") + axisOrientationList[0][1].replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    #This function help us to find the unit of the floor\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #An unit can be m, t , f, meters, tildes, feets\n",
    "    unitList = re.findall(r'\\bt\\b|\\bf\\b|\\bm\\b|\\bu\\b',\" \".join([str(token) for token in next_words]))\n",
    "    unitList += re.findall(\"metre|feet|tilde|unit\",\" \".join([str(token) for token in next_words]))\n",
    "    #If we didn't find any unit, we need to seek it in the second part of the sentence\n",
    "    if len(unitList) ==0:\n",
    "        unitList = re.findall(r'\\bt\\b|\\bf\\b|\\bm\\b|\\bu\\b',\" \".join([str(token) for token in last_words]))\n",
    "        unitList += re.findall(\"metre|feet|tilde|unit\",\" \".join([str(token) for token in last_words]))\n",
    "        \n",
    "        #We should have found an unit\n",
    "        if len(unitList) == 0:\n",
    "            raise Exception(\"There wasn't any unit in the sentence\")\n",
    "    \n",
    "    #If there are many unit, we choose the first one\n",
    "    \n",
    "    return unitList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    #This function seek the hexadecimal color next to the word color (or one of its synonym)\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #A color should be in hexadecimal ==> MAYBE A NAME LATER ??\n",
    "    colorList = re.findall(r'#[ *][A-Z0-9a-z]{6}\\b',\" \".join([str(token) for token in next_words]))\n",
    "    print(colorList)\n",
    "    #If we didn't find a color after the word color, we need to look before\n",
    "    if len(colorList) ==0:\n",
    "        colorList = re.findall(r'#[ *][A-Z0-9a-z]{6}\\b',\" \".join([str(token) for token in last_words]))\n",
    "\n",
    "        #If there isn't any color, we need to raise an execption\n",
    "        if len(colorList) == 0: \n",
    "            raise Exception(\"There wasn't any color\")\n",
    "        \n",
    "    #If there are several colors, we choose the first one\n",
    "    return colorList[0].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a room called ROOM1 with an orientation of -x -y   in u with # abD874 as color   \n",
      "axisOrientation :  -x-y\n",
      "Unit :  u\n",
      "[]\n",
      "Color :  #abD874\n"
     ]
    }
   ],
   "source": [
    "testNlp = nlp(\"create a room called ROOM1 with an orientation of -x -y  in u with #abD874 as color   \")\n",
    "\n",
    "print(\"axisOrientation : \", axisOrientation(testNlp, 0,0,22))\n",
    "print(\"Unit : \", unit(testNlp,0,0,20))\n",
    "print(\"Color : \", color(testNlp,20,10,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(processed_entry : type(nlp(\"\")), index : int, attachedEntity : str, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[float] :\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    previous_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    # TODO : adapt for rack\n",
    "    \n",
    "    isRotationNegative = False\n",
    "    rotation_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "    if not len(rotation_list) == 1 :\n",
    "        rotation_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in previous_words]))\n",
    "        isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "        if not len(rotation_list_left) == 1 :\n",
    "            raise Exception(\"Wrong rotation format entered\")\n",
    "        else :\n",
    "            rotation_list = rotation_list_left\n",
    "    rotationFinal = float(rotation_list[0]) if rotation_list else None\n",
    "    rotationFinal = -rotationFinal if isRotationNegative else rotationFinal\n",
    "    return rotationFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    # TODO : it only works for regular size not sizeXY or sizeU\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    size_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    if not (len(size_list) == 3):\n",
    "        size_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in last_words]))\n",
    "        if not (len(size_list) == 3) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            size_list = size_list_left\n",
    "    result = [float(coord) for coord in size_list] if size_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[str] :\n",
    "    #The template is defined by a name, it's the same structure as for Name() but simplified since there is less convoluted wording\n",
    "    \n",
    "    def findClose(indexToken : int) -> Optional[int] :\n",
    "        if indexToken +1 <= len(processed_entry)-1 :\n",
    "            if processed_entry[indexToken+1].is_upper or processed_entry[indexToken+1].pos_ == \"PROPN\" :\n",
    "                return indexToken+1\n",
    "        if 0 <= indexToken -1 :\n",
    "            if processed_entry[indexToken-1].is_upper or processed_entry[indexToken-1].pos_ == \"PROPN\" :\n",
    "                return indexToken-1\n",
    "        return None\n",
    "\n",
    "    def findAttachedEntity(indexToken : int) -> (bool) : \n",
    "        counter = 0\n",
    "        isFound = False\n",
    "        currentIndex = indexToken\n",
    "        currentWord = processed_entry[currentIndex]\n",
    "        while (not isFound) and counter < 3 :\n",
    "            currentWord = processed_entry[currentIndex].head\n",
    "            currentIndex = currentWord.i\n",
    "            if str(currentWord) in PARAMETERS_DICT[\"template\"] : #Peux Ãªtre faut il passer aux Lemma ?\n",
    "                return True\n",
    "            counter += 1\n",
    "        return False\n",
    "    \n",
    "    EXPLICIT =  PARAMETERS_DICT[\"name\"]\n",
    "\n",
    "    # if the name if right beside the entity\n",
    "    resultIndex = findClose(index)\n",
    "    if resultIndex != None :\n",
    "        return processed_entry[resultIndex]\n",
    "    else: #look in the NProp if one is linked to Template\n",
    "        for indexTemp,tokenTemp in enumerate(processed_entry) : # look for keyword\n",
    "            if processed_entry[indexTemp].is_upper or processed_entry[indexTemp].pos_ == \"PROPN\" :\n",
    "                indexAttachedEntity = findAttachedEntity(indexTemp)\n",
    "                if findAttachedEntity(indexTemp) :\n",
    "                    return tokenTemp\n",
    "            \n",
    "            \"\"\"\n",
    "            # if the token is a synonym of called\n",
    "            if sum([tokenTemp.similarity(nlp(word)[0]) > SIMILARITY_PARAMETER for word in EXPLICIT]) >= 1 :\n",
    "                resultIndex = findClose(indexTemp)\n",
    "                if resultIndex != None :\n",
    "                    indexAttachedEntity = findAttachedEntity(indexTemp)\n",
    "                    if indexAttachedEntity != None :\n",
    "                        resultIndex = indexAttachedEntity\n",
    "                else {\n",
    "                    return resultIndex\n",
    "                }\n",
    "            \"\"\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associateParameters(processed_entry : type(nlp(\"\")), KEY_WORDS_ENTRY : dict, dictEntities : dict) -> dict :\n",
    "    association = {}\n",
    "    for index, keyword in KEY_WORDS_ENTRY.items():\n",
    "        if keyword in KEY_WORDS_DICT.keys():\n",
    "            for ancestor in processed_entry[index].ancestors:\n",
    "                if ancestor.i in dictEntities.keys():\n",
    "                    association[index] = (ancestor.i, keyword)\n",
    "                    break\n",
    "            if not index in association.keys():\n",
    "                association[index] = (INDEX_MAIN_ENTITY, keyword)\n",
    "    return association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : the similarity func is very time-taking, we must shorten the process time or find another way\n",
    "\n",
    "def main() -> str :\n",
    "    FINAL_INSTRUCTION = \"\"\n",
    "\n",
    "    # TODO : add already existing entity names\n",
    "    ENTITIES_FULL_NAME = {\"entity\" : list(wiki.ENTITIES.keys())}\n",
    "    KEY_WORDS_ALL = {**ENTITIES_FULL_NAME,  **PARAMETERS_DICT}\n",
    "\n",
    "    natural_entry = input(\"Enter a prompt. Please follow the instructions given.\\n\")\n",
    "    processed_entry = nlp(natural_entry)\n",
    "\n",
    "    KEY_WORDS_ENTRY = {} \n",
    "    # we detect key words in the sentence given and put them into KEY_WORDS_ENTRY\n",
    "    lastParameter = None\n",
    "    for index,token in enumerate(processed_entry) :\n",
    "        matching_list = [] # list of tuples with the similarity score and type of key word (for each key word)\n",
    "        if token.pos_ == \"VERB\" and str(token) == token.lemma_ : # 2nd test : if infinitive verb\n",
    "            for parameter in ACTIONS_DEFAULT.keys() :\n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in ACTIONS_DEFAULT[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        elif token.pos_ in [\"NOUN\",\"ADP\",\"VERB\"]:\n",
    "            for parameter in KEY_WORDS_ALL.keys() : \n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in KEY_WORDS_ALL[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        else :\n",
    "            continue\n",
    "\n",
    "        match = max(matching_list)\n",
    "\n",
    "        # if \"called\" or a synonym is used for a parameter and not for an entity\n",
    "        if match[1] == \"name\" and (lastParameter == token.head or lastParameter in token.children) :\n",
    "            continue\n",
    "        if match[0] > SIMILARITY_THRESHOLD :\n",
    "            # if is considered a key word, is added to the dict\n",
    "            KEY_WORDS_ENTRY[index] = match[1] \n",
    "            if parameter in PARAMETERS_DICT.keys() :\n",
    "                lastParameter = token\n",
    "\n",
    "    print(KEY_WORDS_ENTRY)\n",
    "\n",
    "    dictEntities = {index : str(processed_entry[index]) for index,keyword in KEY_WORDS_ENTRY.items() if keyword == \"entity\"}\n",
    "    print(dictEntities)\n",
    "\n",
    "    # test detection\n",
    "    list_key_param = list(KEY_WORDS_ENTRY.values())\n",
    "    count_action = 0 # the nb of action words indentified\n",
    "    for action_type in ACTIONS_DEFAULT.keys() :\n",
    "        count_action += list_key_param.count(action_type)\n",
    "\n",
    "    if count_action != 1 :\n",
    "        raise Exception(\"Action not detected\")\n",
    "    else :\n",
    "        global INDEX_ACTION\n",
    "        global INDEX_MAIN_SUBJECT\n",
    "        INDEX_ACTION = [index for index,keyword in KEY_WORDS_ENTRY.items() if keyword in ACTIONS_DEFAULT.keys()][0]\n",
    "        finalRelations = findRelations(processed_entry, dictEntities, INDEX_ACTION)\n",
    "        print(\"relations :\", finalRelations)\n",
    "        INDEX_MAIN_SUBJECT = findIndexMainSubject(processed_entry, INDEX_ACTION, KEY_WORDS_ENTRY)  \n",
    "    print(\"index main : \",INDEX_MAIN_SUBJECT)\n",
    "\n",
    "    dictioEntityNames = name(processed_entry, dictEntities, [INDEX_MAIN_SUBJECT, INDEX_ACTION])\n",
    "    print(\"names : \",dictioEntityNames)\n",
    "\n",
    "    association = associateParameters(processed_entry, KEY_WORDS_ENTRY, dictEntities)\n",
    "    print(\"association between keyword and entity :\", association)\n",
    "\n",
    "    # TODO : match cases (main = entity/parameter, verb = +/alteration...)\n",
    "    if KEY_WORDS_ENTRY[INDEX_MAIN_SUBJECT] == \"entity\" :\n",
    "          # we do the processes related to each parameter\n",
    "        dictioEntityParameters = wiki.makeDictParam(str(processed_entry[INDEX_MAIN_SUBJECT]))\n",
    "        dictioEntityParameters[\"name\"] = str(processed_entry[dictioEntityNames[INDEX_MAIN_SUBJECT]])\n",
    "        allEntryItems = KEY_WORDS_ENTRY.items()\n",
    "        for counter,(index,parameter) in enumerate(allEntryItems) :\n",
    "            if (not parameter in KEY_WORDS_DICT.keys()) or bool(dictioEntityParameters[parameter]) == True :\n",
    "                continue\n",
    "            lastKeyWordIndex = 0 if counter == 0 else list(allEntryItems)[counter-1][0]\n",
    "            nextKeyWordIndex = len(processed_entry) if counter == len(allEntryItems)-1 else list(allEntryItems)[counter+1][0]\n",
    "            # get the parameter value\n",
    "            parameterValue = globals()[parameter](processed_entry, index, lastKeyWordIndex, nextKeyWordIndex)\n",
    "            dictioEntityParameters[parameter] = parameterValue # store the value\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_POSITIVE\" : \n",
    "          \n",
    "\n",
    "            print(dictioEntityParameters)\n",
    "            # TODO : call the class method\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_NEGATIVE\" :\n",
    "            print(dictioEntityParameters)\n",
    "           # TODO : call the class method\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ALTERATION\" :\n",
    "            print(dictioEntityParameters)\n",
    "            # TODO : understand what are the changes and its consequences\n",
    "            pass\n",
    "\n",
    "    if KEY_WORDS_ENTRY[INDEX_MAIN_SUBJECT] in PARAMETERS_DICT.keys() :\n",
    "        # TODO : seek the value to be changed\n",
    "        pass\n",
    "    \n",
    "    # if seeking the name for the main entity, pass the indexaction as parameter\n",
    "    # if no name found, check the type of action : if +, a name is needed, otherwise not necessarily\n",
    "\n",
    "    # check if parameters were not given\n",
    "\n",
    "    # return KEY_WORDS_ENTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ACTION_POSITIVE', 2: 'entity', 3: 'name', 7: 'entity', 12: 'entity', 13: 'name'}\n",
      "{2: 'room', 7: 'building', 12: 'building'}\n",
      "{7: (2, 'appartenance'), 12: (2, 'ERROR')}\n",
      "index main :  2\n",
      "names :  {7: 8, 2: 8, 12: 14}\n",
      "{3: (2, 'name'), 13: (12, 'name')}\n",
      "{'name': 'IMT', 'position': None, 'rotation': None, 'size': None, 'axisOrientation': None, 'floorUnit': None, 'template': None}\n"
     ]
    }
   ],
   "source": [
    "text = \"create, in the site IMT, a building A with 0 0 position\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39670881628990173"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"inside\")[0].similarity(nlp(\"having\")[0])\n",
    "# [nlp(\"current\")[0].similarity(nlp(word)[0]) for word in [\"axis\", \"orientation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07210052758455276\n",
      "0.31477174162864685\n",
      "0.2948082685470581\n",
      "0.307853639125824\n",
      "0.3341883718967438\n",
      "0.0\n",
      "0.0\n",
      "0.1039787158370018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoxy\\AppData\\Local\\Temp\\ipykernel_1520\\299749315.py:11: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  print(nlp(x)[0].similarity(nlp(\"inside\")[0]))\n"
     ]
    }
   ],
   "source": [
    "#Test position, size, rotation, template\n",
    "testNlp = nlp(\"at 0.0 0 create a building named BATIMENT with the dimension 50 40 60, turned by 90 degrees and with the template called FAKER\")\n",
    "testNlp = nlp(\"make a room called Nowhere in the building IMT next to the building named Centrale\")\n",
    "testNlp = nlp(\"create a room named NOWHERE at 0 0 next to the room positioned at 15 25\")\n",
    "# testNlp = nlp(\"make the room called Nowhere in the building IMT next to the building named Centrale\")\n",
    "\n",
    "# print(\"Position :\" + str(position(testNlp, 0, 0, 4, \"building\")))\n",
    "# print(\"Rotation :\" + str(rotation(testNlp, 15, 11, 19, \"building\")))\n",
    "# print(\"Dimension :\" + str(size(testNlp, 10, 6, 14, \"building\")))\n",
    "# print(\"Template :\" + str(template(testNlp, 22, 19, 23, \"building\")))\n",
    "\n",
    "for x in PARAMETERS_DICT.keys() :\n",
    "    print(nlp(x)[0].similarity(nlp(\"inside\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4dc2a224e5034e73a23d1f95e51b20cc-0\" class=\"displacy\" width=\"2850\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">create</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">room</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">named</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">NOWHERE</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">0</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">0</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">next</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">room</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">positioned</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">15</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">25</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-0\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,266.5 L403.0,254.5 387.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oprd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-7\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oprd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-10\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,266.5 L1978.0,254.5 1962.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-11\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,177.0 2140.0,177.0 2140.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,266.5 L2148.0,254.5 2132.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-12\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2315.0,266.5 L2323.0,254.5 2307.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-13\" stroke-width=\"2px\" d=\"M2520,264.5 C2520,177.0 2665.0,177.0 2665.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,266.5 L2512,254.5 2528,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-14\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,89.5 2670.0,89.5 2670.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4dc2a224e5034e73a23d1f95e51b20cc-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2670.0,266.5 L2678.0,254.5 2662.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(testNlp, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"R1\")[0].is_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
