{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc, Token\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import importlib\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import ogree_wiki as wiki\n",
    "importlib.reload(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_DEFAULT = {\n",
    "                    \"ACTION_POSITIVE\" : [\"make\",\"build\",\"put\",\"place\"],\n",
    "                    \"ACTION_NEGATIVE\" : [\"remove\", \"delete\"], \n",
    "                    \"ALTERATION\" : [\"modify\", \"change\",\"move\",\"set\",\"rename\",\"rotate\"]\n",
    "                    }\n",
    "\n",
    "ACTIONS_CLI = {\n",
    "                \"ACTION_POSITIVE\" : \"+\",\n",
    "                \"ACTION_NEGATIVE\" : \"-\"\n",
    "                }\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.5\n",
    "\n",
    "PARAMETERS_DICT = {\n",
    "            \"name\" : [\"name\",\"called\"],\n",
    "            \"position\" : [\"position\",\"at\",\"located\"],\n",
    "            \"rotation\" : [\"rotation\",\"turned\",\"degree\"],\n",
    "            \"size\" : [\"size\",\"dimensions\"],\n",
    "            \"template\" : [\"template\"],\n",
    "            \"axisOrientation\" : [\"axisOrientation\", \"axis\", \"orientation\"],\n",
    "            \"slot\" : [\"slot\"],\n",
    "            \"color\" : [\"color\"], #Est-ce qu'on rajoute des couleurs genre red, green, grey, ...?\n",
    "            \"unit\" :  [\"unit\"],    # C'est quoi le mieux ? [\"t\",\"m\",\"f\",'metre', \"tilde\", \"feet\"],\n",
    "            \"side\" : [\"side\"],\n",
    "            \"temperature\" : [\"temperature\", \"°C\", \"K\", \"F\"],\n",
    "            \"reserved\" : [\"reserved\"],\n",
    "            \"technical\" : [\"technical\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexMainSubject(processed_entry : Doc, dictioIndexKeyWords : dict, indexAction : int, indexMainEntity : int = None) -> int :\n",
    "\n",
    "    def searchSubjectRecursive(processed_entry : Doc, currentIndex : int, testConformity, level : int = 0) -> (list|None):\n",
    "        if level == 5 :\n",
    "            return None\n",
    "        if testConformity(processed_entry[currentIndex]) :\n",
    "            return [(currentIndex, level)]\n",
    "        else:\n",
    "            childList = []\n",
    "            for child in processed_entry[currentIndex].children :\n",
    "                childResult = searchSubjectRecursive(processed_entry, child.i, testConformity, level+1)\n",
    "                if childResult != None :\n",
    "                    childList.extend(childResult)\n",
    "            if bool(childList) == True : # if the list is not empty    \n",
    "                minValue = min(childList, key=lambda x: x[1])[1]\n",
    "                return [x for x in childList if x[1] == minValue] \n",
    "            return childList\n",
    "        \n",
    "    # def testConformityMain(token : Token) -> bool :\n",
    "    #     if token.i in dictioIndexKeyWords.keys() and token.pos_ != \"VERB\":\n",
    "    #         return True\n",
    "    #     return False\n",
    "    \n",
    "    def testConformity(token : Token) -> bool :\n",
    "        if ((token.i in dictioIndexKeyWords.keys() or token.pos_ == \"NOUN\") \n",
    "            and token.pos_ != \"VERB\"\n",
    "            and not token.is_upper) :\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    actionType = dictioIndexKeyWords[indexAction]\n",
    "    # testConformity = testConformityAlteration if actionType == \"ALTERATION\" else testConformityMain\n",
    "\n",
    "    result = searchSubjectRecursive(processed_entry, indexAction, testConformity)\n",
    "    result = [x[0] for x in result]\n",
    "    resultLength = len(result)\n",
    "\n",
    "    if resultLength == 0 :\n",
    "        raise Exception(\"Main request not identified\")\n",
    "    elif resultLength == 1 :\n",
    "        return result[0]\n",
    "    else : # if there are at least two tokens at the same length from the action\n",
    "\n",
    "        if actionType == \"ALTERATION\" : # if alteration, prioritize known parameters\n",
    "            resultOnlyParameters = [index for index in result if dictioIndexKeyWords[index] in PARAMETERS_DICT.keys()]\n",
    "            if bool(resultOnlyParameters) :\n",
    "                return resultOnlyParameters[0]\n",
    "            else :\n",
    "                return result[0]\n",
    "            \n",
    "        else : # prioritize entities\n",
    "            resultOnlyEntity = [index for index in result if dictioIndexKeyWords[index] == \"entity\"]\n",
    "            if not bool(resultOnlyEntity) :\n",
    "                return result[0]\n",
    "            elif len(resultOnlyEntity) == resultLength and indexMainEntity in result :\n",
    "                return indexMainEntity\n",
    "            else :\n",
    "                return resultOnlyEntity[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the relation is coherent, according to the relation\n",
    "def testRelation(index1 : int, index2 : int, relationType : str, hierarchyPosition : dict) -> bool :\n",
    "    if relationType == \"hierarchy\" and hierarchyPosition[index2] < hierarchyPosition[index1]:\n",
    "        return True\n",
    "    elif relationType == \"location\" and hierarchyPosition[index2] == hierarchyPosition[index1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def findIndexMainEntity(processed_entry : Doc, dictEntities : dict, indexAction : int) -> int :\n",
    "    counter = 0\n",
    "    currentIndexes = {index:index for index in dictEntities.keys()}\n",
    "    currentWords = {index:processed_entry[index] for index in currentIndexes.keys()}\n",
    "\n",
    "    while (not indexAction in currentIndexes.values()) and counter < 3 :\n",
    "        currentWords = {originIndex : processed_entry[currentIndex].head for originIndex,currentIndex in currentIndexes.items()}\n",
    "        currentIndexes = {originIndex : currentWords[originIndex].i for originIndex,_ in currentIndexes.items()}\n",
    "\n",
    "        if list(currentIndexes.values()).count(indexAction) == 1 :\n",
    "            return [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction][0]\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 3 :\n",
    "        raise Exception(\"Main entity not found\")\n",
    "    \n",
    "    if list(currentIndexes.values()).count(indexAction) != 1 :\n",
    "        listIndexesRemaining = [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction and originIndex > indexAction]\n",
    "        return listIndexesRemaining[0]\n",
    "    else :\n",
    "        return [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction][0]\n",
    "\n",
    "\n",
    "def findRelations(processed_entry : Doc, dictEntities : dict, indexAction : int) -> dict :\n",
    "\n",
    "    RELATIONS = {\n",
    "        \"hierarchy\" : [\"in\", \"inside\"],\n",
    "        \"location\" : [\"next\"]\n",
    "    }\n",
    "    \n",
    "    dictRelations = {index : None for index in dictEntities.keys()} # empty dict that will be filled\n",
    "\n",
    "    # go through the ancestors and check if there's a synonym of the relation key words\n",
    "    for index in dictEntities.keys() :\n",
    "        for ancestor in processed_entry[index].ancestors :\n",
    "            for relation in RELATIONS.keys() :\n",
    "                if max([ancestor.similarity(nlp(word)[0]) > SIMILARITY_THRESHOLD for word in RELATIONS[relation]]) :\n",
    "                    dictRelations[index] = relation\n",
    "                    break\n",
    "\n",
    "    global INDEX_MAIN_ENTITY\n",
    "\n",
    "    # if zero or more than 1 entities don't have a relation\n",
    "    withoutRelationCounter = list(dictRelations.values()).count(None)\n",
    "    if  withoutRelationCounter != 1 :\n",
    "        dictWithoutRelations = {index : relation for (index,relation) in dictRelations.items() if relation == None}\n",
    "        if withoutRelationCounter == 0 :\n",
    "            dictWithoutRelations = dictEntities\n",
    "        INDEX_MAIN_ENTITY = findIndexMainEntity(processed_entry, dictWithoutRelations, indexAction)\n",
    "\n",
    "    # if only one entity is not attached to a relation keyword, it's the main one\n",
    "    else :\n",
    "        INDEX_MAIN_ENTITY = [index for index,relation in dictRelations.items() if relation == None][0]\n",
    "\n",
    "    # the hierarchy position : 0 is site, 3 is rack... etc\n",
    "    hierarchyPosition = {index : list(wiki.ENTITIES.keys()).index(entity) for index, entity in dictEntities.items()}\n",
    "    finalRelations = dict()\n",
    "\n",
    "    # for all entities except the main one, we assign the related entity according to the relation\n",
    "    for index, relation in dictRelations.items() : \n",
    "        if index == INDEX_MAIN_ENTITY:\n",
    "            continue\n",
    "        for token in processed_entry[index].ancestors :\n",
    "            if token.i in dictEntities.keys(): \n",
    "                if testRelation(token.i, index, relation, hierarchyPosition):\n",
    "                    finalRelations[index] = (token.i, relation)\n",
    "                else:\n",
    "                    finalRelations[index] = (token.i, \"ERROR\")\n",
    "                break\n",
    "            elif token.i == indexAction:\n",
    "                if testRelation(INDEX_MAIN_ENTITY, index, relation, hierarchyPosition):\n",
    "                    finalRelations[index] = (INDEX_MAIN_ENTITY, relation)\n",
    "                else:\n",
    "                    finalRelations[index] = (INDEX_MAIN_ENTITY, \"ERROR\")\n",
    "                break\n",
    "        if not index in finalRelations :\n",
    "            finalRelations[index] = (INDEX_MAIN_ENTITY, relation)\n",
    "\n",
    "    return finalRelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(processed_entry : Doc, dictioEntities : dict, listNameSynonyms : list, indexesMain : dict) -> int :\n",
    "\n",
    "    def isName(token : Token) -> bool :\n",
    "        if token.is_upper or token.pos_ == \"PROPN\" :\n",
    "            return True\n",
    "        return False   \n",
    "\n",
    "    def findClose(processed_entry : Doc, index : int) -> (int|None) :\n",
    "        if index +1 <= len(processed_entry)-1 and isName(processed_entry[index+1]) :\n",
    "            return index+1\n",
    "        if 0 <= index -1 and isName(processed_entry[index-1]):\n",
    "            return index-1\n",
    "        return None\n",
    "\n",
    "    def findAttachedEntity(processed_entry : Doc, index : int) -> (int|None) : \n",
    "        counter = 0\n",
    "        for token in processed_entry[index].ancestors :\n",
    "            if counter == 3 :\n",
    "                break\n",
    "            if token.i in dictioEntities.keys() and token.i not in dictioEntityNames.keys() :\n",
    "                return token.i\n",
    "            if token.i == indexesMain[\"action\"] :\n",
    "                return indexesMain[\"entity\"]\n",
    "            counter += 1\n",
    "        return None\n",
    "\n",
    "    EXPLICIT =  PARAMETERS_DICT[\"name\"]\n",
    "    IMPLICIT = [\"current\",\"main\"]\n",
    "\n",
    "    dictioEntityNames = {} # dict with entityIndex : NameOfTheEntityIndex\n",
    "\n",
    "    # begin with the synonyms of \"called\"\n",
    "    for nameSynonymIndex in listNameSynonyms :\n",
    "        currentToken = processed_entry[nameSynonymIndex]\n",
    "        attachedEntityIndex = findAttachedEntity(processed_entry, nameSynonymIndex)\n",
    "        attachedValueIndex = None\n",
    "\n",
    "        if attachedEntityIndex == None or attachedEntityIndex in dictioEntityNames.keys() :\n",
    "            continue\n",
    "\n",
    "        if (currentToken.similarity(nlp(\"called\")[0]) > SIMILARITY_THRESHOLD\n",
    "            and currentToken.i < len(list(processed_entry))-1\n",
    "            and currentToken.is_ancestor(processed_entry[currentToken.i +1])) :\n",
    "            attachedValueIndex = currentToken.i +1\n",
    "\n",
    "        if len(list(currentToken.children)) != 0  and attachedValueIndex == None :\n",
    "            for token in currentToken.rights :\n",
    "                if isName(token) :\n",
    "                    attachedValueIndex = token.i\n",
    "                    break\n",
    "            if attachedValueIndex == None :\n",
    "                for token in currentToken.lefts :\n",
    "                    if isName(token) :\n",
    "                        attachedValueIndex = token.i # we choose the rightmost\n",
    "\n",
    "        if len(list(currentToken.ancestors)) != 0 and attachedValueIndex == None :\n",
    "            counter = 0\n",
    "            for token in currentToken.ancestors :\n",
    "                if counter == 2 :\n",
    "                    break\n",
    "                if isName(token) :\n",
    "                    attachedValueIndex = token.i\n",
    "            \n",
    "        if attachedValueIndex != None and attachedValueIndex not in dictioEntityNames.values() :            \n",
    "            dictioEntityNames[attachedEntityIndex] = attachedValueIndex\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if not all names found\n",
    "\n",
    "        # if the name if right beside the entity\n",
    "        for entityIndex,_ in dictioEntities.items() :\n",
    "            if entityIndex in dictioEntityNames.keys() :\n",
    "                continue\n",
    "            attachedValueIndex = findClose(processed_entry, entityIndex)\n",
    "            if attachedValueIndex != None and attachedValueIndex not in dictioEntityNames.values() :\n",
    "                dictioEntityNames[entityIndex] = attachedValueIndex\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if not all names found\n",
    "\n",
    "        for token in processed_entry : # look directly for a name\n",
    "\n",
    "            if isName(token) :\n",
    "                indexAttachedEntity = findAttachedEntity(processed_entry, token.i)\n",
    "                if (indexAttachedEntity not in dictioEntityNames.keys()\n",
    "                    and token.i not in dictioEntityNames.values()\n",
    "                    and indexAttachedEntity != None) :\n",
    "                    dictioEntityNames[indexAttachedEntity] = token.i\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if still not all names found\n",
    "        pass\n",
    "    # TODO : get current names\n",
    "\n",
    "    # TODO : check for implicit words now\n",
    "    \n",
    "    return dictioEntityNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(processed_entry : Doc, index : int, attachedEntity : str, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    previous_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    LENGTH_CRITERIA = 2\n",
    "    if attachedEntity == \"device\" :\n",
    "        LENGTH_CRITERIA = 1\n",
    "    position_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in next_words]))\n",
    "    if not (len(position_list) == LENGTH_CRITERIA or (len(position_list) == 3 and attachedEntity == \"rack\")):\n",
    "        position_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in previous_words]))\n",
    "        if not (len(position_list) == LENGTH_CRITERIA or (len(position_list) == 3 and attachedEntity == \"rack\")) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            position_list = position_list_left\n",
    "    result = [float(coord) for coord in position_list] if position_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(processed_entry : Doc, index : int, attachedEntity : str, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[float] :\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    previous_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    # TODO : adapt for rack\n",
    "    \n",
    "    isRotationNegative = False\n",
    "    rotation_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in next_words]))\n",
    "    isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([token.text for token in next_words]))\n",
    "    if not len(rotation_list) == 1 :\n",
    "        rotation_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in previous_words]))\n",
    "        isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([token.text for token in next_words]))\n",
    "        if not len(rotation_list_left) == 1 :\n",
    "            raise Exception(\"Wrong rotation format entered\")\n",
    "        else :\n",
    "            rotation_list = rotation_list_left\n",
    "    rotationFinal = float(rotation_list[0]) if rotation_list else None\n",
    "    rotationFinal = -rotationFinal if isRotationNegative else rotationFinal\n",
    "    return rotationFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size(processed_entry : Doc, index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    # TODO : it only works for regular size not sizeXY or sizeU\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    size_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in next_words]))\n",
    "    if not (len(size_list) == 3):\n",
    "        size_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([token.text for token in last_words]))\n",
    "        if not (len(size_list) == 3) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            size_list = size_list_left\n",
    "    result = [float(coord) for coord in size_list] if size_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axisOrientation(processed_entry : Doc, index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    # We search the axis Orientation\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #An axis Orientation  can be any combinason of [+/-]x[+/-]y. eg: +x+y or -x+y\n",
    "    print(\" \".join([token.text for token in next_words]))\n",
    "    axisOrientationList =  re.findall(\" (-x|\\+[ *]x)[ *](-y|\\+[ *]y)\", \" \".join([token.text for token in next_words]))\n",
    "    #If we didn't find an axis orientation, we need to seek it in the second part of the sentence\n",
    "    if len(axisOrientationList) ==0 :\n",
    "        axisOrientationList = re.findall(\"(-x|\\+[ *]x)[ *](-y|\\+[ *]y)\", \" \".join([token.text for token in last_words]))\n",
    "        #If we still didn't find it, we need to raise an error\n",
    "        if len(axisOrientationList) ==0 :\n",
    "            raise Exception(\"Wrong axisOrientation format entered\")\n",
    "    \n",
    "    #We need to raise an error if we find only one coordonate\n",
    "    if len(axisOrientationList[0]) < 2:\n",
    "        raise Exception(\"Only one coordinate was found\")\n",
    "    #Even if several axis Orientations where found, we always take the first one\n",
    "    return axisOrientationList[0][0].replace(\" \", \"\") + axisOrientationList[0][1].replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit(processed_entry : Doc, index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    #This function help us to find the unit of the floor\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #An unit can be m, t , f, meters, tildes, feets\n",
    "    unitList = re.findall(r'\\bt\\b|\\bf\\b|\\bm\\b|\\bu\\b',\" \".join([token.text for token in next_words]))\n",
    "    unitList += re.findall(\"metre|feet|tilde|unit\",\" \".join([token.text for token in next_words]))\n",
    "    #If we didn't find any unit, we need to seek it in the second part of the sentence\n",
    "    if len(unitList) ==0:\n",
    "        unitList = re.findall(r'\\bt\\b|\\bf\\b|\\bm\\b|\\bu\\b',\" \".join([token.text for token in last_words]))\n",
    "        unitList += re.findall(\"metre|feet|tilde|unit\",\" \".join([token.text for token in last_words]))\n",
    "        \n",
    "        #We should have found an unit\n",
    "        if len(unitList) == 0:\n",
    "            raise Exception(\"There wasn't any unit in the sentence\")\n",
    "    \n",
    "    #If there are many unit, we choose the first one\n",
    "    \n",
    "    return unitList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(processed_entry : Doc, index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[list] :\n",
    "    #This function seek the hexadecimal color next to the word color (or one of its synonym)\n",
    "    #We slit the sentence in two parts\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    #A color should be in hexadecimal ==> MAYBE A NAME LATER ??\n",
    "    colorList = re.findall(r'#[ *][A-Z0-9a-z]{6}\\b',\" \".join([token.text for token in next_words]))\n",
    "    print(colorList)\n",
    "    #If we didn't find a color after the word color, we need to look before\n",
    "    if len(colorList) ==0:\n",
    "        colorList = re.findall(r'#[ *][A-Z0-9a-z]{6}\\b',\" \".join([token.text for token in last_words]))\n",
    "\n",
    "        #If there isn't any color, we need to raise an execption\n",
    "        if len(colorList) == 0: \n",
    "            raise Exception(\"There wasn't any color\")\n",
    "        \n",
    "    #If there are several colors, we choose the first one\n",
    "    return colorList[0].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNlp = nlp(\"create a room called ROOM1 with an orientation of -x -y  in u with #abD874 as color   \")\n",
    "\n",
    "print(\"axisOrientation : \", axisOrientation(testNlp, 0,0,22))\n",
    "print(\"Unit : \", unit(testNlp,0,0,20))\n",
    "print(\"Color : \", color(testNlp,20,10,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template(processed_entry : Doc, index : int, lastKeyWordIndex : int, nextKeyWordIndex : int) -> Optional[str] :\n",
    "    #The template is defined by a name, it's the same structure as for Name() but simplified since there is less convoluted wording\n",
    "    \n",
    "    def findClose(indexToken : int) -> Optional[int] :\n",
    "        if indexToken +1 <= len(processed_entry)-1 :\n",
    "            if processed_entry[indexToken+1].is_upper or processed_entry[indexToken+1].pos_ == \"PROPN\" :\n",
    "                return indexToken+1\n",
    "        if 0 <= indexToken -1 :\n",
    "            if processed_entry[indexToken-1].is_upper or processed_entry[indexToken-1].pos_ == \"PROPN\" :\n",
    "                return indexToken-1\n",
    "        return None\n",
    "\n",
    "    def findAttachedEntity(indexToken : int) -> (bool) : \n",
    "        counter = 0\n",
    "        isFound = False\n",
    "        currentIndex = indexToken\n",
    "        currentWord = processed_entry[currentIndex]\n",
    "        while (not isFound) and counter < 3 :\n",
    "            currentWord = processed_entry[currentIndex].head\n",
    "            currentIndex = currentWord.i\n",
    "            if currentWord.text in PARAMETERS_DICT[\"template\"] : #Peux être faut il passer aux Lemma ?\n",
    "                return True\n",
    "            counter += 1\n",
    "        return False\n",
    "    \n",
    "    EXPLICIT =  PARAMETERS_DICT[\"name\"]\n",
    "\n",
    "    # if the name if right beside the entity\n",
    "    resultIndex = findClose(index)\n",
    "    if resultIndex != None :\n",
    "        return processed_entry[resultIndex]\n",
    "    else: #look in the NProp if one is linked to Template\n",
    "        for indexTemp,tokenTemp in enumerate(processed_entry) : # look for keyword\n",
    "            if processed_entry[indexTemp].is_upper or processed_entry[indexTemp].pos_ == \"PROPN\" :\n",
    "                indexAttachedEntity = findAttachedEntity(indexTemp)\n",
    "                if findAttachedEntity(indexTemp) :\n",
    "                    return tokenTemp\n",
    "            \n",
    "            \"\"\"\n",
    "            # if the token is a synonym of called\n",
    "            if sum([tokenTemp.similarity(nlp(word)[0]) > SIMILARITY_PARAMETER for word in EXPLICIT]) >= 1 :\n",
    "                resultIndex = findClose(indexTemp)\n",
    "                if resultIndex != None :\n",
    "                    indexAttachedEntity = findAttachedEntity(indexTemp)\n",
    "                    if indexAttachedEntity != None :\n",
    "                        resultIndex = indexAttachedEntity\n",
    "                else {\n",
    "                    return resultIndex\n",
    "                }\n",
    "            \"\"\"\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associateParameters(processed_entry : Doc, KEY_WORDS_ENTRY : dict, dictEntities : dict, dictioEntityNames : dict) -> dict :\n",
    "    association = {}\n",
    "    if len(dictEntities) == 1:\n",
    "        for index, keyword in KEY_WORDS_ENTRY.items():\n",
    "            association[index] = (INDEX_MAIN_ENTITY, keyword)\n",
    "        return association\n",
    "    for index, keyword in KEY_WORDS_ENTRY.items():\n",
    "        if keyword in PARAMETERS_DICT.keys():\n",
    "            if len(dictEntities) == len(dictioEntityNames):\n",
    "                if keyword != \"name\":\n",
    "                    association[index] = (INDEX_MAIN_ENTITY, keyword)\n",
    "                else:\n",
    "                    for ancestor in processed_entry[index].ancestors:\n",
    "                        if ancestor.i in dictEntities.keys() and not((ancestor.i, keyword) in association.values()):\n",
    "                            association[index] = (ancestor.i, keyword)\n",
    "                            print(\"here entity\")\n",
    "                            break\n",
    "            else:\n",
    "                if keyword == \"name\":\n",
    "                    for ancestor in processed_entry[index].ancestors:\n",
    "                        if ancestor.i in dictEntities.keys() and not((ancestor.i, keyword) in association.values()):\n",
    "                            association[index] = (ancestor.i, keyword)\n",
    "                            print(\"here entity\")\n",
    "                            break\n",
    "                else:\n",
    "                    for ancestor in processed_entry[index].ancestors:\n",
    "                        if (ancestor.i, \"name\") in list(association.values()):\n",
    "                            continue\n",
    "                        if ancestor.i in KEY_WORDS_ENTRY.keys() and KEY_WORDS_ENTRY[ancestor.i] == \"name\":\n",
    "                            association[index] = ([ancestor.i], keyword)\n",
    "                            print(\"here name\")\n",
    "                            break\n",
    "                        if ancestor.i in dictEntities.keys() and not((ancestor.i, keyword) in association.values()):\n",
    "                            association[index] = (ancestor.i, keyword)\n",
    "                            print(\"here entity\")\n",
    "                            break\n",
    "            if not index in association.keys():\n",
    "                association[index] = (INDEX_MAIN_ENTITY, keyword)\n",
    "    for index, (index2, parameterType) in association.items():\n",
    "        if type(index2) == list:\n",
    "            association[index] = (association[index2[0]][0], parameterType)\n",
    "    return association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : the similarity func is very time-taking, we must shorten the process time or find another way\n",
    "\n",
    "def main() -> str :\n",
    "    FINAL_INSTRUCTION = \"\"\n",
    "\n",
    "    # TODO : add already existing entity names\n",
    "    ENTITIES_FULL_NAME = {\"entity\" : list(wiki.ENTITIES.keys())}\n",
    "    KEY_WORDS_ALL = {**ENTITIES_FULL_NAME,  **PARAMETERS_DICT}\n",
    "\n",
    "    natural_entry = input(\"Enter a prompt. Please follow the instructions given.\\n\")\n",
    "    processed_entry = nlp(natural_entry)\n",
    "\n",
    "    KEY_WORDS_ENTRY = {} \n",
    "    # we detect key words in the sentence given and put them into KEY_WORDS_ENTRY\n",
    "    lastParameter = None\n",
    "    for index,token in enumerate(processed_entry) :\n",
    "        matching_list = [] # list of tuples with the similarity score and type of key word (for each key word)\n",
    "        if token.pos_ == \"VERB\" and str(token) == token.lemma_ : # 2nd test : if infinitive verb\n",
    "            for parameter in ACTIONS_DEFAULT.keys() :\n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in ACTIONS_DEFAULT[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        elif token.pos_ in [\"NOUN\",\"ADP\",\"VERB\"]:\n",
    "            for parameter in KEY_WORDS_ALL.keys() : \n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in KEY_WORDS_ALL[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        else :\n",
    "            continue\n",
    "\n",
    "        match = max(matching_list)\n",
    "\n",
    "        # if \"called\" or a synonym is used for a parameter and not for an entity\n",
    "        if match[1] == \"name\" and (lastParameter == token.head or lastParameter in token.children) :\n",
    "            continue\n",
    "        if match[0] > SIMILARITY_THRESHOLD :\n",
    "            # if is considered a key word, is added to the dict\n",
    "            KEY_WORDS_ENTRY[index] = match[1] \n",
    "            if match[1] in PARAMETERS_DICT.keys() :\n",
    "                lastParameter = token\n",
    "\n",
    "    print(KEY_WORDS_ENTRY)\n",
    "\n",
    "    dictEntities = {index : processed_entry[index].text for index,keyword in KEY_WORDS_ENTRY.items() if keyword == \"entity\"}\n",
    "    print(dictEntities)\n",
    "\n",
    "    # test detection\n",
    "    list_key_param = list(KEY_WORDS_ENTRY.values())\n",
    "    count_action = 0 # the nb of action words indentified\n",
    "    for action_type in ACTIONS_DEFAULT.keys() :\n",
    "        count_action += list_key_param.count(action_type)\n",
    "\n",
    "    if count_action != 1 :\n",
    "        raise Exception(\"Action not detected\")\n",
    "    \n",
    "    # TODO : check entities\n",
    "    # if no entity :check the ocli file\n",
    "    global INDEX_ACTION\n",
    "    global INDEX_MAIN_SUBJECT\n",
    "    INDEX_ACTION = [index for index,keyword in KEY_WORDS_ENTRY.items() if keyword in ACTIONS_DEFAULT.keys()][0]\n",
    "    finalRelations = findRelations(processed_entry, dictEntities, INDEX_ACTION)\n",
    "    print(\"finalRelations : \", finalRelations)\n",
    "    INDEX_MAIN_SUBJECT = findIndexMainSubject(processed_entry, KEY_WORDS_ENTRY, INDEX_ACTION, INDEX_MAIN_ENTITY)  \n",
    "    print(\"index main subject : \", INDEX_MAIN_SUBJECT)\n",
    "\n",
    "    INDEXES_MAIN = {\"subject\" : INDEX_MAIN_SUBJECT, \n",
    "                    \"action\" : INDEX_ACTION, \n",
    "                    \"entity\" : INDEX_MAIN_ENTITY}\n",
    "\n",
    "    dictioEntityNames = name(processed_entry,\n",
    "                             dictEntities,\n",
    "                             [index for index,parameter in KEY_WORDS_ENTRY.items() if parameter == \"name\"],\n",
    "                             INDEXES_MAIN)\n",
    "    print(\"names : \",dictioEntityNames)\n",
    "\n",
    "    # TODO : get the full name e.g. P/BASIC/COCK\n",
    "\n",
    "    if INDEX_MAIN_SUBJECT not in KEY_WORDS_ENTRY.keys() :\n",
    "        # TODO : the dectection is different (key word set TO)\n",
    "        pass\n",
    "    \n",
    "    association = associateParameters(processed_entry, KEY_WORDS_ENTRY, dictEntities, dictioEntityNames)\n",
    "    print(\"association between keyword and entity :\", association)\n",
    "\n",
    "    # TODO : match cases (main = entity/parameter, verb = +/alteration...)\n",
    "    if KEY_WORDS_ENTRY[INDEX_MAIN_SUBJECT] == \"entity\" :\n",
    "        # we do the processes related to each parameter\n",
    "        \n",
    "        dictioEntityParameters = wiki.makeDictParam(processed_entry[INDEX_MAIN_SUBJECT].text)\n",
    "        dictioEntityParameters[\"name\"] = processed_entry[dictioEntityNames[INDEX_MAIN_SUBJECT]].text.upper()\n",
    "        allEntryItemsList = list(KEY_WORDS_ENTRY.items())\n",
    "        for counter,(index,parameter) in enumerate(allEntryItemsList) :\n",
    "            if (not parameter in PARAMETERS_DICT.keys()) or bool(dictioEntityParameters[parameter]) == True :\n",
    "                continue\n",
    "            lastKeyWordIndex = 0 if counter == 0 else allEntryItemsList[counter-1][0]\n",
    "            nextKeyWordIndex = len(processed_entry) if counter == len(allEntryItemsList)-1 else allEntryItemsList[counter+1][0]\n",
    "            # get the parameter value\n",
    "            parameterValue = globals()[parameter](processed_entry, index, lastKeyWordIndex, nextKeyWordIndex)\n",
    "            dictioEntityParameters[parameter] = parameterValue # store the value\n",
    "        print(dictioEntityParameters)\n",
    "\n",
    "    \n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_POSITIVE\" : \n",
    "            pass\n",
    "            # TODO : call the class method\n",
    "            # REQUIRES : all the code beyond \n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_NEGATIVE\" :\n",
    "            pass\n",
    "            # TODO : call the class method\n",
    "            # REQUIRES : just the full name\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ALTERATION\" :\n",
    "\n",
    "            # TODO\n",
    "            # REQUIRES : the full name, the parameter and its value\n",
    "            pass\n",
    "    \n",
    "    # if seeking the name for the main entity, pass the indexaction as parameter\n",
    "    # if no name found, check the type of action : if +, a name is needed, otherwise not necessarily\n",
    "\n",
    "    # check if parameters were not given\n",
    "\n",
    "    # return KEY_WORDS_ENTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNlp5 = nlp(\"put a rack in a room named A2 which is called R1 with dimension 3 4 2 rotated by 45 45 45\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"name\")[0].similarity(nlp(\"called\")[0])\n",
    "# TODO : nlp(\"dimensions\")[0].similarity(nlp(\"complexity\")[0])\n",
    "# [nlp(\"current\")[0].similarity(nlp(word)[0]) for word in [\"axis\", \"orientation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test position, size, rotation, template\n",
    "testNlp1 = nlp(\"create the building named BATIMENT with the dimension 50 40 60, turned by 90 degrees and with the template called intel640\")\n",
    "testNlp2 = nlp(\"make a room called Nowhere in the building IMT next to the building named Centrale\")\n",
    "testNlp3 = nlp(\"set the complexity of the room R1 to easy\")\n",
    "testNlp4 = nlp(\"in the site IMT, create a room with R1 as name\")\n",
    "testNlp5 = nlp(\"put a rack in a room named A2 which is called R1 with dimension 3 4 2 rotated by 45 45 45\")\n",
    "testNlp6 = nlp(\"create the parameter codepostal for the room R1 with value 01170\")\n",
    "testNlp7 = nlp(\"put a rack called R1 in a room named A2 with dimension 3 4 2 rotated by 45 45 45\")\n",
    "testNlp8 = nlp(\"in the site S1, in the building B1, create a room R1\")\n",
    "testNlp9 = nlp(\"put a rack called R1 in a room with dimension 3 4 2 rotated by 45 45 45\")\n",
    "\n",
    "# print(\"Position :\" + str(position(testNlp, 0, 0, 4, \"building\")))\n",
    "# print(\"Rotation :\" + str(rotation(testNlp, 15, 11, 19, \"building\")))\n",
    "# print(\"Dimension :\" + str(size(testNlp, 10, 6, 14, \"building\")))\n",
    "# print(\"Template :\" + str(template(testNlp, 22, 19, 23, \"building\")))\n",
    "\n",
    "iter(testNlp4[5].ancestors)\n",
    "dictio = {1 : (\"a\", \"b\"), 2 : (\"c\", \"d\")}\n",
    "print(list(dictio.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.render(testNlp9, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
