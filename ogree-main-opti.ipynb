{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ogree_wiki' from 'c:\\\\Users\\\\thoxy\\\\OneDrive\\\\Documents\\\\IMT-PJENT\\\\OGrEE_NLP\\\\ogree_wiki.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import importlib\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import ogree_wiki as wiki\n",
    "importlib.reload(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_DEFAULT = {\n",
    "                    \"ACTION_POSITIVE\" : [\"make\",\"build\",\"put\",\"place\"],\n",
    "                    \"ACTION_NEGATIVE\" : [\"remove\", \"delete\"], \n",
    "                    \"ALTERATION\" : [\"modify\", \"change\",\"move\",\"set\",\"rename\",\"rotate\"]\n",
    "                    }\n",
    "\n",
    "ACTIONS_CLI = {\n",
    "                \"ACTION_POSITIVE\" : \"+\",\n",
    "                \"ACTION_NEGATIVE\" : \"-\"\n",
    "                }\n",
    "\n",
    "SIMILARITY_PARAMETER = 0.5\n",
    "\n",
    "KEY_WORDS_DICT = {\n",
    "            \"name\" : [\"name\",\"called\"],\n",
    "            \"position\" : [\"position\",\"at\",\"located\"],\n",
    "            \"rotation\" : [\"rotation\",\"turned\",\"degree\"],\n",
    "            \"size\" : [\"size\",\"dimensions\"],\n",
    "            \"template\" : [\"template\"],\n",
    "            \"axisOrientation\" : [\"axis\", \"orientation\"],\n",
    "            \"floorUnit\" : [\"floor\",\"unit\"],\n",
    "            \"slot\" : [\"slot\"]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexAction(processed_entry : type(nlp(\"\")), indexAction : int, list_index_entities : list) -> int :\n",
    "    # identify relations for each entity recognized\n",
    "    currentIndexes = list_index_entities[::]\n",
    "    counter = 0\n",
    "    while counter < 3 :\n",
    "        for i in range(len(list_index_entities)) :\n",
    "            currentWord = processed_entry[currentIndexes[i]].head\n",
    "            currentIndexes[i] = list(processed_entry).index(currentWord)\n",
    "        counter += 1\n",
    "\n",
    "    currentIndexesBool = [index == indexAction for index in currentIndexes]\n",
    "    if sum(currentIndexesBool) >= 2 :\n",
    "        currentIndexDistance = [(abs(indexAction - list_index_entities[i]),list_index_entities[i]) for i in range(len(currentIndexes)) if currentIndexesBool[i] == True]\n",
    "        return min(currentIndexDistance)[1]\n",
    "    elif sum(currentIndexesBool) == 1:\n",
    "        return list_index_entities[currentIndexesBool.index(True)]\n",
    "    else :\n",
    "        raise Exception(\"Interpretation issue : no relation found, please try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexMainSubject(processed_entry : type(nlp(\"\")), indexAction : int, dictioIndexKeyWords : dict) -> int :\n",
    "\n",
    "    counter = 0\n",
    "    currentIndexes = {index:index for index,parameter in dictioIndexKeyWords.items() if parameter not in ACTIONS_DEFAULT.keys()}\n",
    "    currentWords = {index:processed_entry[index] for index,parameter in dictioIndexKeyWords.items() if parameter not in ACTIONS_DEFAULT.keys()}\n",
    "    while (not indexAction in currentIndexes.values()) and counter < 3 :\n",
    "        currentWords = {originIndex : processed_entry[currentIndex].head for originIndex,currentIndex in currentIndexes.items()}\n",
    "        currentIndexes = {originIndex : list(processed_entry).index(currentWords[originIndex]) for originIndex,_ in currentIndexes.items()}\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 3 :\n",
    "        raise Exception(\"Did not find the main action\")\n",
    "    \n",
    "    if list(currentIndexes.values()).count(indexAction) != 1 :\n",
    "        listIndexesRemaining = [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction and originIndex > indexAction]\n",
    "        return listIndexesRemaining[0]\n",
    "    else :\n",
    "        return [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(processed_entry : type(nlp(\"\")), dictioEntities : dict, indexesMain : list) -> int :\n",
    "\n",
    "    def findClose(processed_entry : type(nlp(\"\")), index : int) -> (int|None) :\n",
    "        if index +1 <= len(processed_entry)-1 :\n",
    "            if str(processed_entry[index+1]).isupper() or processed_entry[index+1].pos_ == \"PROPN\" :\n",
    "                return index+1\n",
    "        if 0 <= index -1 :\n",
    "            if str(processed_entry[index-1]).isupper() or processed_entry[index-1].pos_ == \"PROPN\" :\n",
    "                return index-1\n",
    "        return None\n",
    "    \n",
    "\n",
    "    def findAttachedEntity(processed_entry : type(nlp(\"\")), index : int) -> (int|None) : \n",
    "        counter = 0\n",
    "        isFound = False\n",
    "        currentIndex = index\n",
    "        currentWord = processed_entry[currentIndex]\n",
    "        while (not isFound) and counter < 3 :\n",
    "            currentWord = processed_entry[currentIndex].head\n",
    "            currentIndex = list(processed_entry).index(currentWord)\n",
    "            if str(currentWord) in dictioEntities.values() :\n",
    "                return currentIndex\n",
    "            if currentWord.pos_ == \"VERB\" and currentIndex == indexesMain[1] : \n",
    "                return indexesMain[0]\n",
    "            counter += 1\n",
    "        return None\n",
    "    \n",
    "    EXPLICIT =  KEY_WORDS_DICT[\"name\"]\n",
    "    IMPLICIT = [\"current\",\"main\"]\n",
    "\n",
    "    dictioEntityNames = {}\n",
    "        \n",
    "    for index,entity in dictioEntities.items() :\n",
    "    # if the name if right beside the entity\n",
    "        resultIndex = findClose(processed_entry, index)\n",
    "        if resultIndex != None :\n",
    "            dictioEntityNames[index] = resultIndex\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if not all names found\n",
    "\n",
    "        for index,token in enumerate(processed_entry) : # look for keyword\n",
    "\n",
    "            if str(processed_entry[index]).isupper() or processed_entry[index].pos_ == \"PROPN\" :\n",
    "                indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                    dictioEntityNames[indexAttachedEntity] = index\n",
    "            \n",
    "            # if the token is a synonym of called\n",
    "            if sum([token.similarity(nlp(word)[0]) > SIMILARITY_PARAMETER for word in EXPLICIT]) >= 1 :\n",
    "                resultIndex = findClose(processed_entry, index)\n",
    "                if resultIndex != None :\n",
    "                    indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                    if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                        dictioEntityNames[indexAttachedEntity] = resultIndex\n",
    "\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if still not all names found\n",
    "        pass\n",
    "    # TODO : get current names\n",
    "    \n",
    "    return dictioEntityNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int, entity : str) -> Optional[list] :\n",
    "    # search for keywords to the right and left to split whole sentence into parts where to look for param entries\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    \n",
    "    position_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    if not (len(position_list) == 2 or (len(position_list) == 3 and entity == \"rack\")):\n",
    "        position_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in last_words]))\n",
    "        if not (len(position_list) == 2 or (len(position_list) == 3 and entity == \"rack\")) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            position_list = position_list_left\n",
    "    result = [float(coord) for coord in position_list] if position_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int, entity : str) -> Optional[float] :\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    \n",
    "    isRotationNegative = False\n",
    "    rotation_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "    if not len(rotation_list) == 1 :\n",
    "        rotation_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in last_words]))\n",
    "        isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "        if not len(rotation_list_left) == 1 :\n",
    "            raise Exception(\"Wrong rotation format entered\")\n",
    "        else :\n",
    "            rotation_list = rotation_list_left\n",
    "    rotationFinal = float(rotation_list[0]) if rotation_list else None\n",
    "    rotationFinal = -rotationFinal if isRotationNegative else rotationFinal\n",
    "    return rotationFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int, entity : str) -> Optional[list] :\n",
    "    #it only works for regular size not sizeXY or sizeU\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "\n",
    "    size_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    if not (len(size_list) == 3):\n",
    "        size_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in last_words]))\n",
    "        if not (len(position_list) == 3) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            position_list = position_list_left\n",
    "    result = [float(coord) for coord in position_list] if position_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : the similarity func is very long, we must shorten the process time or find another way\n",
    "\n",
    "def main() -> str :\n",
    "    FINAL_INSTRUCTION = \"\"\n",
    "\n",
    "    ENTITIES_FULL_NAME = {\"entity\" : list(wiki.ENTITIES.keys())}\n",
    "\n",
    "    # TODO : add already existing entity names\n",
    "    KEY_WORDS_ALL = {**ENTITIES_FULL_NAME,  **KEY_WORDS_DICT}\n",
    "    KEY_WORDS_ENTRY = {}\n",
    "\n",
    "    natural_entry = input(\"Enter a prompt. Please follow the instructions given.\\n\")\n",
    "    processed_entry = nlp(natural_entry)\n",
    "\n",
    "    # we detect key words in the sentence given and put them into KEY_WORDS_ENTRY\n",
    "    for index,token in enumerate(processed_entry) :\n",
    "        matching_list = []\n",
    "        if token.pos_ == \"VERB\" :\n",
    "            for parameter in ACTIONS_DEFAULT.keys() :\n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in ACTIONS_DEFAULT[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        elif token.pos_ == \"NOUN\":\n",
    "            for parameter in KEY_WORDS_ALL.keys() : \n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in KEY_WORDS_ALL[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        else :\n",
    "            continue\n",
    "        match = max(matching_list)\n",
    "        if match[0] > SIMILARITY_PARAMETER :\n",
    "            KEY_WORDS_ENTRY[index] = match[1]\n",
    "\n",
    "    print(KEY_WORDS_ENTRY)\n",
    "\n",
    "    # test detection\n",
    "    list_key_param = list(KEY_WORDS_ENTRY.values())\n",
    "    count_action = 0\n",
    "    for action_type in ACTIONS_DEFAULT.keys() :\n",
    "        count_action += list_key_param.count(action_type)\n",
    "\n",
    "    if count_action != 1 :\n",
    "        raise Exception(\"Action not detected\")\n",
    "    if count_action == 1 :\n",
    "        global INDEX_ACTION\n",
    "        global INDEX_MAIN_SUBJECT\n",
    "        INDEX_ACTION = [index for index,keyword in KEY_WORDS_ENTRY.items() if keyword in ACTIONS_DEFAULT.keys()][0]\n",
    "        INDEX_MAIN_SUBJECT = findIndexMainSubject(processed_entry, INDEX_ACTION, KEY_WORDS_ENTRY)  \n",
    "    print(\"index main : \",INDEX_MAIN_SUBJECT)\n",
    "\n",
    "    dictEntities = {index : str(processed_entry[index]) for index,keyword in KEY_WORDS_ENTRY.items() if keyword == \"entity\"}\n",
    "    print(dictEntities)\n",
    "\n",
    "    # TODO : match cases (main = entity/parameter, verb = +/alteration...)\n",
    "\n",
    "    # test number of names ?\n",
    "\n",
    "    # then we do the processes related to each key word\n",
    "    dictioIfDone = wiki.makeDictParam(str(processed_entry[INDEX_MAIN_SUBJECT]))\n",
    "    for index,parameter in KEY_WORDS_ENTRY.items() :\n",
    "        if (not KEY_WORDS_ENTRY[index] in KEY_WORDS_DICT.keys()) or dictioIfDone[parameter] == True :\n",
    "            continue\n",
    "        \n",
    "        # locals()[parameter]()\n",
    "        dictioIfDone[parameter] = True\n",
    "\n",
    "    dictioEntityNames = name(processed_entry, dictEntities, [INDEX_MAIN_SUBJECT, INDEX_ACTION])\n",
    "    print(\"names : \",dictioEntityNames)\n",
    "\n",
    "    \n",
    "    # if seeking the name for the main entity, pass the indexaction as parameter\n",
    "    # if no name found, check the type of action : if +, a name is needed, otherwise not necessarily\n",
    "\n",
    "    # check if parameters were not given\n",
    "\n",
    "    return KEY_WORDS_ENTRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'entity', 4: 'ALTERATION', 6: 'position', 9: 'entity'}\n",
      "index main :  6\n",
      "{2: 'site', 9: 'rack'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'position'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thoxy\\OneDrive\\Documents\\IMT-PJENT\\OGrEE_NLP\\ogree-main-opti.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39min the site, change the position of the rack\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m main()\n",
      "\u001b[1;32mc:\\Users\\thoxy\\OneDrive\\Documents\\IMT-PJENT\\OGrEE_NLP\\ogree-main-opti.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(dictEntities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# test number of names ?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# then we do the processes related to each key word\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m dictioIfDone \u001b[39m=\u001b[39m wiki\u001b[39m.\u001b[39;49mmakeDictParam(\u001b[39mstr\u001b[39;49m(processed_entry[INDEX_MAIN_SUBJECT]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m index,parameter \u001b[39min\u001b[39;00m KEY_WORDS_ENTRY\u001b[39m.\u001b[39mitems() :\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoxy/OneDrive/Documents/IMT-PJENT/OGrEE_NLP/ogree-main-opti.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m KEY_WORDS_ENTRY[index] \u001b[39min\u001b[39;00m KEY_WORDS_DICT\u001b[39m.\u001b[39mkeys()) \u001b[39mor\u001b[39;00m dictioIfDone[parameter] \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m :\n",
      "File \u001b[1;32mc:\\Users\\thoxy\\OneDrive\\Documents\\IMT-PJENT\\OGrEE_NLP\\ogree_wiki.py:62\u001b[0m, in \u001b[0;36mmakeDictParam\u001b[1;34m(entity)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmakeDictParam\u001b[39m(entity : \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m :\n\u001b[0;32m     61\u001b[0m     dictio \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 62\u001b[0m     \u001b[39mfor\u001b[39;00m parameter \u001b[39min\u001b[39;00m listAllParameter(entity) :\n\u001b[0;32m     63\u001b[0m         dictio[parameter] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m dictio\n",
      "File \u001b[1;32mc:\\Users\\thoxy\\OneDrive\\Documents\\IMT-PJENT\\OGrEE_NLP\\ogree_wiki.py:67\u001b[0m, in \u001b[0;36mlistAllParameter\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlistAllParameter\u001b[39m(element : \u001b[39mstr\u001b[39m) :\n\u001b[1;32m---> 67\u001b[0m     full_liste \u001b[39m=\u001b[39m PARAMETERS_NAME[element][\u001b[39m\"\u001b[39m\u001b[39mmandatory\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     68\u001b[0m     full_liste\u001b[39m.\u001b[39mextend(PARAMETERS_NAME[element][\u001b[39m\"\u001b[39m\u001b[39moptional\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m element \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbuilding\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mroom\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mrack\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m] :\n",
      "\u001b[1;31mKeyError\u001b[0m: 'position'"
     ]
    }
   ],
   "source": [
    "text = \"in the site, change the position of the rack\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389259696006775"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"name\")[0].similarity(nlp(\"rename\")[0])\n",
    "# [nlp(\"current\")[0].similarity(nlp(word)[0]) for word in [\"axis\", \"orientation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"name\")[0].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
