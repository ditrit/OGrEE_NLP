{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ogree_wiki' from 'c:\\\\Users\\\\thoxy\\\\OneDrive\\\\Documents\\\\IMT-PJENT\\\\OGrEE_NLP\\\\ogree_wiki.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import importlib\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "import ogree_wiki as wiki\n",
    "importlib.reload(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_DEFAULT = {\n",
    "                    \"ACTION_POSITIVE\" : [\"make\",\"build\",\"put\",\"place\"],\n",
    "                    \"ACTION_NEGATIVE\" : [\"remove\", \"delete\"], \n",
    "                    \"ALTERATION\" : [\"modify\", \"change\",\"move\",\"set\",\"rename\",\"rotate\"]\n",
    "                    }\n",
    "\n",
    "ACTIONS_CLI = {\n",
    "                \"ACTION_POSITIVE\" : \"+\",\n",
    "                \"ACTION_NEGATIVE\" : \"-\"\n",
    "                }\n",
    "\n",
    "SIMILARITY_PARAMETER = 0.5\n",
    "\n",
    "KEY_WORDS_DICT = {\n",
    "            \"name\" : [\"name\",\"called\"],\n",
    "            \"position\" : [\"position\",\"at\",\"located\"],\n",
    "            \"rotation\" : [\"rotation\",\"turned\",\"degree\"],\n",
    "            \"size\" : [\"size\",\"dimensions\"],\n",
    "            \"template\" : [\"template\"],\n",
    "            \"axisOrientation\" : [\"axis\", \"orientation\"],\n",
    "            \"floorUnit\" : [\"floor\",\"unit\"],\n",
    "            \"slot\" : [\"slot\"]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexAction(processed_entry : type(nlp(\"\")), indexAction : int, list_index_entities : list) -> int :\n",
    "    # identify relations for each entity recognized\n",
    "    currentIndexes = list_index_entities[::]\n",
    "    counter = 0\n",
    "    while counter < 3 :\n",
    "        for i in range(len(list_index_entities)) :\n",
    "            currentWord = processed_entry[currentIndexes[i]].head\n",
    "            currentIndexes[i] = list(processed_entry).index(currentWord)\n",
    "        counter += 1\n",
    "\n",
    "    currentIndexesBool = [index == indexAction for index in currentIndexes]\n",
    "    if sum(currentIndexesBool) >= 2 :\n",
    "        currentIndexDistance = [(abs(indexAction - list_index_entities[i]),list_index_entities[i]) for i in range(len(currentIndexes)) if currentIndexesBool[i] == True]\n",
    "        return min(currentIndexDistance)[1]\n",
    "    elif sum(currentIndexesBool) == 1:\n",
    "        return list_index_entities[currentIndexesBool.index(True)]\n",
    "    else :\n",
    "        raise Exception(\"Interpretation issue : no relation found, please try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndexMainSubject(processed_entry : type(nlp(\"\")), indexAction : int, dictioIndexKeyWords : dict) -> int :\n",
    "\n",
    "    counter = 0\n",
    "    currentIndexes = {index:index for index,parameter in dictioIndexKeyWords.items() if parameter not in ACTIONS_DEFAULT.keys()}\n",
    "    currentWords = {index:processed_entry[index] for index,parameter in dictioIndexKeyWords.items() if parameter not in ACTIONS_DEFAULT.keys()}\n",
    "    while (not indexAction in currentIndexes.values()) and counter < 3 :\n",
    "        currentWords = {originIndex : processed_entry[currentIndex].head for originIndex,currentIndex in currentIndexes.items()}\n",
    "        currentIndexes = {originIndex : list(processed_entry).index(currentWords[originIndex]) for originIndex,_ in currentIndexes.items()}\n",
    "        counter += 1\n",
    "\n",
    "    if counter == 3 :\n",
    "        raise Exception(\"Did not find the main action\")\n",
    "    \n",
    "    if list(currentIndexes.values()).count(indexAction) != 1 :\n",
    "        # if many options remain, we only consider those at the right of the verb\n",
    "        listIndexesRemaining = [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction and originIndex > indexAction]\n",
    "        return listIndexesRemaining[0]\n",
    "    else :\n",
    "        return [originIndex for originIndex,currentIndex in currentIndexes.items() if currentIndex == indexAction][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(processed_entry : type(nlp(\"\")), dictioEntities : dict, indexesMain : list) -> int :\n",
    "\n",
    "    def findClose(processed_entry : type(nlp(\"\")), index : int) -> (int|None) :\n",
    "        if index +1 <= len(processed_entry)-1 :\n",
    "            if str(processed_entry[index+1]).isupper() or processed_entry[index+1].pos_ == \"PROPN\" :\n",
    "                return index+1\n",
    "        if 0 <= index -1 :\n",
    "            if str(processed_entry[index-1]).isupper() or processed_entry[index-1].pos_ == \"PROPN\" :\n",
    "                return index-1\n",
    "        return None\n",
    "    \n",
    "\n",
    "    def findAttachedEntity(processed_entry : type(nlp(\"\")), index : int) -> (int|None) : \n",
    "        counter = 0\n",
    "        isFound = False\n",
    "        currentIndex = index\n",
    "        currentWord = processed_entry[currentIndex]\n",
    "        while (not isFound) and counter < 3 :\n",
    "            currentWord = processed_entry[currentIndex].head\n",
    "            currentIndex = list(processed_entry).index(currentWord)\n",
    "            if str(currentWord) in dictioEntities.values() :\n",
    "                return currentIndex\n",
    "            if currentWord.pos_ == \"VERB\" and currentIndex == indexesMain[1] : \n",
    "                return indexesMain[0]\n",
    "            counter += 1\n",
    "        return None\n",
    "    \n",
    "    EXPLICIT =  KEY_WORDS_DICT[\"name\"]\n",
    "    IMPLICIT = [\"current\",\"main\"]\n",
    "\n",
    "    dictioEntityNames = {}\n",
    "        \n",
    "    for index,entity in dictioEntities.items() :\n",
    "    # if the name if right beside the entity\n",
    "        resultIndex = findClose(processed_entry, index)\n",
    "        if resultIndex != None :\n",
    "            dictioEntityNames[index] = resultIndex\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if not all names found\n",
    "\n",
    "        for index,token in enumerate(processed_entry) : # look for keyword\n",
    "\n",
    "            if str(processed_entry[index]).isupper() or processed_entry[index].pos_ == \"PROPN\" :\n",
    "                indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                    dictioEntityNames[indexAttachedEntity] = index\n",
    "            \n",
    "            # if the token is a synonym of called\n",
    "            if sum([token.similarity(nlp(word)[0]) > SIMILARITY_PARAMETER for word in EXPLICIT]) >= 1 :\n",
    "                resultIndex = findClose(processed_entry, index)\n",
    "                if resultIndex != None :\n",
    "                    indexAttachedEntity = findAttachedEntity(processed_entry,index)\n",
    "                    if not (indexAttachedEntity in dictioEntityNames or indexAttachedEntity == None) :\n",
    "                        dictioEntityNames[indexAttachedEntity] = resultIndex\n",
    "\n",
    "\n",
    "    if len(dictioEntityNames) < len(dictioEntities) : # if still not all names found\n",
    "        pass\n",
    "    # TODO : get current names\n",
    "\n",
    "    # TODO : check for implicit words now\n",
    "    \n",
    "    return dictioEntityNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int, entity : str) -> Optional[list] :\n",
    "    # search for keywords to the right and left to split whole sentence into parts where to look for param entries\n",
    "    position_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in processed_entry[index+1:nextKeyWordIndex]]))\n",
    "    if not (len(position_list) == 2 or (len(position_list) == 3 and entity == \"rack\")):\n",
    "        position_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in processed_entry[lastKeyWordIndex:index]]))\n",
    "        if not (len(position_list) == 2 or (len(position_list) == 3 and entity == \"rack\")) :\n",
    "            raise Exception(\"Wrong location format entered\")\n",
    "        else :\n",
    "            position_list = position_list_left\n",
    "    result = [float(coord) for coord in position_list] if position_list else None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(processed_entry : type(nlp(\"\")), index : int, lastKeyWordIndex : int, nextKeyWordIndex : int, entity : str) -> Optional[float] :\n",
    "    next_words = processed_entry[index+1:nextKeyWordIndex]\n",
    "    last_words = processed_entry[lastKeyWordIndex:index]\n",
    "    \n",
    "    isRotationNegative = False\n",
    "    rotation_list = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in next_words]))\n",
    "    isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "    if not len(rotation_list) == 1 :\n",
    "        rotation_list_left = re.findall(\"[-]*[0-9]+[.]*[0-9]*\", \" \".join([str(token) for token in last_words]))\n",
    "        isRotationNegative = re.search(\"counter.*clockwise\", \"\".join([str(token) for token in next_words]))\n",
    "        if not len(rotation_list_left) == 1 :\n",
    "            raise Exception(\"Wrong rotation format entered\")\n",
    "        else :\n",
    "            rotation_list = rotation_list_left\n",
    "    rotationFinal = float(rotation_list[0]) if rotation_list else None\n",
    "    rotationFinal = -rotationFinal if isRotationNegative else rotationFinal\n",
    "    return rotationFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : the similarity func is very long, we must shorten the process time or find another way\n",
    "\n",
    "def main() -> str :\n",
    "    FINAL_INSTRUCTION = \"\"\n",
    "\n",
    "    ENTITIES_FULL_NAME = {\"entity\" : list(wiki.ENTITIES.keys())}\n",
    "\n",
    "    # TODO : add already existing entity names\n",
    "    KEY_WORDS_ALL = {**ENTITIES_FULL_NAME,  **KEY_WORDS_DICT}\n",
    "    KEY_WORDS_ENTRY = {}\n",
    "\n",
    "    natural_entry = input(\"Enter a prompt. Please follow the instructions given.\\n\")\n",
    "    processed_entry = nlp(natural_entry)\n",
    "\n",
    "    # we detect key words in the sentence given and put them into KEY_WORDS_ENTRY\n",
    "    for index,token in enumerate(processed_entry) :\n",
    "        matching_list = []\n",
    "        if token.pos_ == \"VERB\" :\n",
    "            for parameter in ACTIONS_DEFAULT.keys() :\n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in ACTIONS_DEFAULT[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        elif token.pos_ == \"NOUN\":\n",
    "            for parameter in KEY_WORDS_ALL.keys() : \n",
    "                similarity = max([token.similarity(nlp(word)[0]) for word in KEY_WORDS_ALL[parameter]])\n",
    "                matching_list.append((similarity,parameter))\n",
    "        else :\n",
    "            continue\n",
    "        match = max(matching_list)\n",
    "        if match[0] > SIMILARITY_PARAMETER :\n",
    "            KEY_WORDS_ENTRY[index] = match[1]\n",
    "\n",
    "    print(KEY_WORDS_ENTRY)\n",
    "\n",
    "    # test detection\n",
    "    list_key_param = list(KEY_WORDS_ENTRY.values())\n",
    "    count_action = 0\n",
    "    for action_type in ACTIONS_DEFAULT.keys() :\n",
    "        count_action += list_key_param.count(action_type)\n",
    "\n",
    "    if count_action != 1 :\n",
    "        raise Exception(\"Action not detected\")\n",
    "    else :\n",
    "        global INDEX_ACTION\n",
    "        global INDEX_MAIN_SUBJECT\n",
    "        INDEX_ACTION = [index for index,keyword in KEY_WORDS_ENTRY.items() if keyword in ACTIONS_DEFAULT.keys()][0]\n",
    "        INDEX_MAIN_SUBJECT = findIndexMainSubject(processed_entry, INDEX_ACTION, KEY_WORDS_ENTRY)  \n",
    "    print(\"index main : \",INDEX_MAIN_SUBJECT)\n",
    "\n",
    "    dictEntities = {index : str(processed_entry[index]) for index,keyword in KEY_WORDS_ENTRY.items() if keyword == \"entity\"}\n",
    "    print(dictEntities)\n",
    "    dictioEntityNames = name(processed_entry, dictEntities, [INDEX_MAIN_SUBJECT, INDEX_ACTION])\n",
    "    print(\"names : \",dictioEntityNames)\n",
    "\n",
    "    # TODO : match cases (main = entity/parameter, verb = +/alteration...)\n",
    "    if KEY_WORDS_ENTRY[INDEX_MAIN_SUBJECT] == \"entity\" :\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_POSITIVE\" : \n",
    "            # we do the processes related to each parameter\n",
    "            dictioParameters = wiki.makeDictParam(str(processed_entry[INDEX_MAIN_SUBJECT]))\n",
    "            for index,parameter in KEY_WORDS_ENTRY.items() :\n",
    "                if (not KEY_WORDS_ENTRY[index] in KEY_WORDS_DICT.keys()) or bool(dictioParameters[parameter]) == True :\n",
    "                    continue\n",
    "                print(\"here\")\n",
    "                parameterValue = locals()[parameter]()\n",
    "                dictioParameters[parameter] = parameterValue\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ACTION_NEGATIVE\" :\n",
    "            # TODO : only check if the entity is well detected\n",
    "            pass\n",
    "\n",
    "        if KEY_WORDS_ENTRY[INDEX_ACTION] == \"ALTERATION\" :\n",
    "            # TODO : understand what are the changes and its consequences\n",
    "            pass\n",
    "\n",
    "    if KEY_WORDS_ENTRY[INDEX_MAIN_SUBJECT] in KEY_WORDS_DICT.keys() :\n",
    "        # TODO : seek the value to be changed\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "    # if seeking the name for the main entity, pass the indexaction as parameter\n",
    "    # if no name found, check the type of action : if +, a name is needed, otherwise not necessarily\n",
    "\n",
    "    # check if parameters were not given\n",
    "\n",
    "    return KEY_WORDS_ENTRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ACTION_POSITIVE', 2: 'entity'}\n",
      "index main :  2\n",
      "{2: 'building'}\n",
      "names :  {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'ACTION_POSITIVE', 2: 'entity'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389259696006775"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"name\")[0].similarity(nlp(\"rename\")[0])\n",
    "# [nlp(\"current\")[0].similarity(nlp(word)[0]) for word in [\"axis\", \"orientation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
